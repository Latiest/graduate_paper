\chapter{基于transformer的气井产量预测算法}
在气井的全生命周期任务中，气井产量预测可以帮助企业有效规划气井的开发和生产过程，确定最佳的生产速率，以避免资源浪费和确保气井的长期稳定产出。同时，
准确的产气量预测有助于企业评估气井的经济价值，从而做出更加明智的投资决策，比如决定是否继续开发新的气田或是对现有气井进行增产操作。在制定策略时，了解
未来的产气量可以帮助企业更有效地分配资源，比如人力、资金和设备，确保这些资源被投入到最有价值和最需要的地方。并有助于在有风险的情况下识别潜在的生产下
降风险和其他相关风险，使企业能够及时调整策略以降低损失。气井产气量预测是根据气井的生产动态历史数据，对气井未来一段时间内的产能做出准确评估。过去比较广泛
的进行产量预测的方法为预测气井的绝对无阻流量或者通过下降曲线分析的快速方法来匹配生产率-时间历史数据。但是这些现有的用于非常规储量估算的产量递减评估技术
具有潜在的局限性和一些特定假设，如对于间歇生产气井难以进行预测，这可能导致估计错误。本文采用时间序列预测的方式，目前油气产量时间序列预测的研究大多是同步
时间序列预测，应用场景有限。例如：不能实现使用井的静态参数及已知生产曲线预测未来生产曲线，也不能结合训练好的模型来优化生产设计。基于这些痛点，本章借鉴
了TFT的算法，同时根据企业的专家经验设计了网络模型，完成了气井产气量的时间序列预测任务。
\section{问题分析}
气井产量预测要求根据不同气井的历史产气量数据，构建预测模型；在推理阶段，模型能够对任一指定气井未来一段时间内的单日产气量做出预测。

在时间序列预测中，协变
量（covariates）是指与时间序列相关的其他变量。这些变量可以影响时间序列的行为和变化，因此在时间序列预测中使用协变量可以提高预测的准确性。协变量可以是任
何与时间序列相关的变量，包括经济指标、天气数据、人口统计数据等。例如，假设我们正在预测某个城市未来一周的销售额。此时，可以考虑将天气数据作为协变量，因为
天气可能会影响人们购买某些产品的决策。

气井产量预测任务可以抽象为一个多时间序列预测问题(约1000个时间序列)，使用变量包括静态协变量(气井号，井丛号，集气站号，气井类别)，随时间变化的协变量
(Time-dependent Inputs)，可以细分为过去可知，未来不可知的协变量(Past-observed Inputs)，如油压，套压，井口温度，以及过去和未来都可知的协变量
(Apriori-known Future Inputs)，如气井已经生产的天数，每日开井时间。此处，每日开井时间是一个影响产气量的重要因素，因为若开井时间为0，则产气量必定
为0。未来时刻的开关井时间受人工调控开关井的影响，是可知的，因此可以设置为过去和未来都可知的协变量。
\section{问题描述}
\subsection{单井产气量预测问题描述}
对于单个气井，其输入是气井一段时间的产量数据及对应的气井动态数据。对于单井一段时间内的数据，将其记为
\begin{equation}
    \left\{\left(x^1_{\delta}, x^1_{\rho}, x^1_{\sigma}, x^1_{\tau}, x^1_{h}, Y^1_{\phi}\right), \left(x^2_{\delta}, 
    x^2_{\rho}, x^2_{\sigma}, x^2_{\tau}, x^{2}_{h}, Y^2_{\phi}\right), \ldots, \left(x^T_{\delta}, x^T_{\rho}, x^T_{\sigma}, 
    x^T_{\tau}, x^{T}_{h}, Y^T_{\phi}\right)\right\}
    \label{eq:singlewell}
\end{equation}
其中\( N \)表示气井数据的总时间长度，其中上标$i$表示时刻$i$，下标表示不同的特征，分别如下所示：油压\( \delta \)、套压\( \rho \)、
井口温度\( \sigma \)、投产天数\( \tau \)、每日开井时间$h$、日产量$\phi$。则问题可以定义为：基于气井过去一段时间内的油压\( \delta \)等数据来预测气井未来一段时间内的产量，记要预测的未来时间步长$t$。形式化
地描述如公式\eqref{eq:sinpredic}所示。输入为。
\begin{equation}
    \begin{aligned}
        \left\{\left(x^1_{\delta}, x^1_{\rho}, x^1_{\sigma}, x^1_{\tau}, x^1_{h}, Y^1_{\phi}\right), \left(x^2_{\delta}, 
        x^2_{\rho}, x^2_{\sigma}, x^2_{\tau}, x^{2}_{h}, Y^2_{\phi}\right), \ldots, \left(x^T_{\delta}, x^T_{\rho}, x^T_{\sigma}, 
        x^T_{\tau}, x^{T}_{h}, Y^T_{\phi}\right), \left(x^{T+1}_{\tau}, x^{T+1}_{h}\right),\ldots, \left(x^{T+t}_{\tau}, 
        x^{T+t}_{h}\right)\right\}
    \end{aligned}
    \label{eq:sinpredic}
\end{equation}
输出为$\left\{ y^{T+1}_{\phi}, y^{T+2}_{\phi}, \ldots, y^{T+t}_{\phi} \right\}$。

对于时序数据预测问题，需要将一整条数据依据时间点划分为训练数据和测试数据，然后需要设置训练数据步长与滑动步长，从而生成多个样本。因此为将问题转换为时间
序列问题，需设置新的符合并对问题作进一步地定义。需要将记训练数据输入步长为$T$,$T$通常大于等于要预测的时间步长$t$,记滑动步长为$s$,记训练数据和测试数
据的划分时间点为$N_0$，记
\subsection{多井产气量预测问题描述}
现有产气量预测方法多为针对某一单一气井的建模，应用价值有限。每个气井的产量主控因素可能有较大差别，且很多参数是无法量化的，无法加入到机器学习中，带来了
较大的不确定性。因此，通过某一单一气井时间序列数据训练出的机器学习模型往往无法针对其他气井使用。

同时，对于本企业提供的气井数据集而言，一共包含1000余口气井的时间序列数据。一方面，要针对单一气井构建不同的时间序列模型是不现实的，单井的数据量是有限的，且部分气井仅具
有极少量数据，无法据此构建机器学习/深度学习模型，且模型过多会导致通用性差，难以管理等问题。另一方面，使用所有气井的数据集进行训练可以捕捉到不同气井之
间具有的相似的生产规律，提高了模型泛化性，实现了对多气井产气量预测的统一建模。

本文的多气井产气量预测在单井产气量预测的基础上添加一系列静态协变量(包括气井号，井丛号，集气站号和气井类别)，并针对第三章得到的不同类别的气井生成特定类别的预测结果。因此多气井产量预测模型在
考虑了气井预测模型的泛化性的基础上又不失特殊性，从而实现了气井产量的高效预测。
\section{算法框架}
根据上文所述内容，需要根据气井的历史数据信息来预测气井的未来产量。本文借鉴了TFT的框架，并根据企业的气井数据特征来对TFT的模型进行了一些改进。具体
的算法框架如图\ref{fig:TFTprogess}所示。
\begin{figure}[H]
    \label{fig:TFTprogess}
    \caption{基于transformer的气井产量预测算法流程图}
\end{figure}
本章提出的气井产量预测算法具体分为以下几个步骤：
（1）气井数据提取：本章使用企业提供的气井数据，并在第\ref{cha:data}章中对气井数据进行了数据清洗，使得其可以直接在接下来进行数据处理。

（2）气井数据预处理：使用滑动窗口对气井数据进行处理，接下来对数据进行无量纲化处理，将所有特征缩放至$[0,1]$之间。最终把得到数据集用于后续模型的训练、验证和测试。

（3）获取气井类别：根据第三章的方式对气井进行分类，以根据气井在地质特征、井深、压力水平和历史产量等不同条件下分类的结果分别进行预测。

（4）使用基于transformer的方式对每类气井分别进行预测：根据气井不同的协变量，将输入的历史时刻和未来时刻的特征经过一系列变换，得到一个抽象的
表征，然后分别输入到Encoder和Decoder中。Encoder部分使用GRU网络来编码历史时刻的信息，输出一个固定长度的向量，表示整个历史序列的含义。
Decoder部分使用自注意力机制来解码未来时刻的预测值，每个预测值都是根据之前所有时刻的加权结果得到的，这样可以提高模型的准确性。
\section{数据处理及分类}
\label{sec:datafoc}
气井的数据在第\ref{cha:data}章已经选取了日期，集气站号，井序号，日产时间，井口压力(油压)，套压，井口温度，日产量和投产时间等数据存储在了一
个名为GasProductionOri.csv的文件中。

但是此时的到的每条时间序列都过长，直接建模可能会由于计算资源的限制而变得不可行。为了统一输入输出格式，
降低模型复杂度和计算开销，本文使用滑动窗口技术将
训练数据切割为固定长度。滑动窗口模式是进行序列预测问题处理的最常用也是最有效方式，通过控制窗口的大小，可以调整参与预测的历史数据的数量。其模型如
图\ref{fig:slidewindow}所示。
\begin{figure}[H]
    \label{fig:slidewindow}
    \caption{滑动窗口数据分段示意图}
\end{figure}
如图\ref{fig:slidewindow}所示,设置滑动间隔为1，使用固定大小为4的滑动窗口，对气井的时间序列进行划分。在取出样本序列后，每个样本分段的数据差异大且复杂，
未经标准化处理的样本分段会导致机器学习模型的学习速度十分缓慢，甚至无法更新模型参数。同时，由于不同分段之间的差异，数值较大的分段可能会对模型的决策过程产生
不成比例的影响，导致模型偏向于这些数据，从而影响预测结果的准确性。我们需要对每个样本分段进行无量纲化处理，将所有特征放缩至$[0,1]$之间,即
\begin{equation}
    y = \frac{x - \text{min}}{\text{max} - \text{min}}
\end{equation}
其中$min$为该分段中的最小值，$max$为该分段中的最大值。

气井会因为它们的地理位置、地质构造、开采历史和技术等因素而表现出不同的产量特性。直接在所有气井数据上建立预测模型的话，模型就会过于复杂，难以捕捉到每一种类型气井的特点。而分类后，为每一类气
井建立模型可以简化问题，使得模型更容易泛化，减少过拟合的风险。同时，通过基于改进的K-Shape时间序列聚类算法对气井进行分类以后，可以将具
有相似产量特征的气井分为一组，使得预测模型能够专注于这些相似特征，从而提高预测准确性。第三章将气井分为 类，本章将分别对其进行产量预测。
\section{算法主要设计策略}
如图\ref{fig:TFT}所示，为基于transformer的气井产量预测算法的模型结构图。
\begin{figure}
    \label{fig:TFT}
    \caption{基于transformer的气井产量预测算法的模型结构图}
\end{figure}
由图中可知，网络模型主要由门控残差网络、输入层、时间特征处理层、时域注意力层、position-wise前馈层以及分位数预测层组成。
\subsection{门控残差网络}
\label{cha:GRN}
由于输入与目标之间的关系是未知的，对于预测结果而言，到底需要什么程度的非线性处理是一项巨大的挑战。非线性层过多会出现梯度消失或梯度爆炸的问题，因此，有时
需要简化模型来处理问题。为了让模型只在需要的时候才灵活地应用非线性地方式处理数据，我们提出了门控残差网络来处理数据。门控残差网络的输入为主输入$\mathbf{a}$
和一个可选的上下文向量$\mathbf{c}$。具体操作如下所示：
\begin{equation}
    GRN_{\omega}(\mathbf{a}, \mathbf{c}) = \text{LayerNorm}(\mathbf{a} + GLU_{\omega}(\boldsymbol{\eta}_1))
\end{equation}
其中：
\begin{equation}
    \boldsymbol{\eta}_1 = \mathbf{W}_{1,\omega} \boldsymbol{\eta}_2 + \mathbf{b}_{1,\omega}
\end{equation}
\begin{equation}
    \boldsymbol{\eta}_2 = \text{ELU}(\mathbf{W}_{2,\omega} \mathbf{a} + \mathbf{W}_{3,\omega} \mathbf{c} + \mathbf{b}_{2,\omega})
    \label{eq:eta2}
\end{equation}
上式中，ELU是指线性激活函数，$\eta_1 \in \mathbb{R}^{d_{\text{model}}}$, $\eta_2 \in \mathbb{R}^{d_{\text{model}}}$ 是中间层，
LayerNorm是于2016年被提出的标准归一化，$\omega$ 是表示权重共享的索引。当$\mathbf{W}_{2,\omega} \mathbf{a} + \mathbf{W}_{3,\omega} \mathbf{c} + \mathbf{b}_{2,\omega} \gg 0$时，
ELU激活函数将作为恒等函数，而当$\mathbf{W}_{2,\omega} \mathbf{a} + \mathbf{W}_{3,\omega} \mathbf{c} + \mathbf{b}_{2,\omega} \ll 0$ 时，ELU激活函数产生一个固定的输出，直接触发线性层的行为。我们使用基于门控线性单元 (GLUs)的组件门控层来
提供灵活性，以抑制数据集中不需要的任何体系结构。假设 $\boldsymbol{\gamma } \in \mathbb{R}^{d_{\text{model}}}$ 是输入，GLU的形式为：
\begin{equation}
    GLU_{\omega}(\boldsymbol{\gamma }) = \sigma(\mathbf{W}_{4,\omega} \mathbf{\boldsymbol{\gamma }} + \mathbf{b}_{4,\omega}) \odot (\mathbf{W}_{5,\omega} \mathbf{\boldsymbol{\gamma }} + \mathbf{b}_{5,\omega}),
\end{equation}
其中 $\sigma(\cdot)$ 是sigmoid激活函数，$\mathbf{W}_{(\cdot)} \in \mathbb{R}^{d_{\text{model}} \times d_{\text{model}}}$ 是权重，$\mathbf{b}_{(\cdot)} \in \mathbb{R}^{d_{\text{model}}}$ 是偏置，
$\odot $ 是元素的Hadamard乘积。GLU允许模型控制GRN对原始输入$\mathbf{a}$的贡献程度--如果必要，GLU的输出可以都接近于0，以便抑制模型非线性
的贡献。对于没有上下文向量$\mathbf{c}$的实例，GRN简单地将上下文输入视为0（即在\eqref{eq:eta2}中，$\mathbf{c}=0$）。
\subsection{输入层}
本模型将融合了多种数据源。具体地由图中可知：输入层包括三种类型的变量。最左侧的$S$是静态变量，包括气井号、井丛号、集气站号和气井类别。从$x_{t-k}$到$x_t$代表的是从过去$k$时刻已知
，但未来不可知的随时间变化的变量，包括井口温度，油压，套压，日产量等。最右侧的$x_{t+1}$到$x_{t+\tau_{max}} $代表的是从过去$t-k$到未来$t+\tau_{max}$时刻
都可知的随时间变化的变量，包括已经投产的天数，每日开井时长等。

其中静态变量$S$需要经过静态协变量编码器来整合来自静态元数据的信息。具体地，本文使用\ref{cha:GRN}所展示的门控残差网络来编码产生上下文向量$\mathbf{c}_h$
，$\mathbf{c}_h$将传入时间特征的局部处理层作为GRU的初始输入。
\subsection{时间特征处理层}
在时间序列的数据中，重要的点例如异常、变化点或者周期性模式一般都是根据他们周围的值来识别的。通过编码时间序列能够在序列中记忆和使用先前的信息，增强局
部上下文，从而提高基于注意力架构模型的性能。本文将采用序列到序列层来进行时间序列编码，TFT使用LSTM来对时间序列进行编码，但是LSTM参数量相对较多，其包
括更多的门控单元。这会导致在训练和推理过程中需要更多的计算资源，特别是气井数据集的规模较大。尽管LSTM设计用来更好地捕捉长期依赖关系，但有时候它会
受到梯度消失或爆炸的影响，导致难以有效地学习长期依赖，这可能需要额外的技巧或者调整来解决。基于以上痛点，本文使用GRU来对时间序列进行编码。
GRU具有更简单的结构，它合并了LSTM的遗忘门和输入门，因此参数数量较少。这使得GRU在训练和推理过程中的计算效率更高。且其有更快的训练速度，。这使得在大规
模数据集上进行实验和调整参数时更加高效。我们将过去的输入序列$\bm{\xi}_{t-k:k}$提供给编码器，将未来的输入序列$\bm{\xi}_{t+1:t+\tau_{max}}$
提供给解码器。使用GRU生成一组均匀的时间特征，作为下一阶段的输入，用$\phi (t,n)$来表示，
其中$\phi(t,n) \in {\phi(t, -k), \ldots, \phi(t, T_{\text{max}})}$，$n$是位置指标。这种方式也可以完美处理观测到的过去和未来的输入不同而
存在的差异。同时，为了让静态数据也参与到时间序列变量的编码中，我们使用$\mathbf{c_h}$上下文向量初始化第一个GRU的隐藏状态。在此处也使用门控跳跃链接：
\begin{equation}
    \tilde{\bm{\phi}}(t, n) = \text{LayerNorm}\left(\tilde{\bm{\xi}}_{t+n} + \text{GLU}_{\tilde{\phi}}(\bm{\phi}(t, n))\right)
\end{equation}
其中$n \in [ -k, \tau_{\max}]$是位置指标。
\subsection{时域注意力层}
在进行GRU编码后，我们采用自注意力来学习不同时间步之间的长期关系。传统的多头注意力每个头使用不同的值，仅通过权重注意力本身并不能指示特定特征的重要性，此处
在传统多头注意力的基础上共享V。具体如下：
一般来说，注意力机制基于键矩阵\( K \in \mathbb{R}^{N \times d_{\text{attn}}} \)和查询矩阵\( Q \in \mathbb{R}^{N \times d_{\text{attn}}} \)
之间的关系对值\( V \in \mathbb{R}^{N \times d_v} \)进行缩放：
\begin{equation}
    \text{Attention}(Q, K, V) = A(Q,K)V
\end{equation}
其中$A()$是一个归一化函数，\( N \) 是进入注意力层的时间步数（即 \( k + t_{\text{max}} \)）。常用的选择是缩放点积注意力：
\begin{equation}
    A(Q, K) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d_{\text{attn}}}}\right)
\end{equation}
为了提高注意力机制的学习能力，Vaswani于2017年提出了多头注意力，使用不同的头针对不同的表示子空间：
\begin{equation}
    \text{MultiHead}(Q, K, V) = [H_1, \ldots, H_m]W_H
\end{equation}
\begin{equation}
    H_h = \text{Attention}(QW^Q_{(h)}, KW^K_{(h)}, VW^V_{(h)})
\end{equation}
其中\( W^K_{(h)} \in \mathbb{R}^{d_{\text{model}} \times d_{\text{attn}}} \), \( W^Q_{(h)} \in \mathbb{R}^{d_{\text{model}} \times d_{\text{attn}}} \), \( W^V_{(h)} \in \mathbb{R}^{d_{\text{model}} \times d_v} \) 
是针对键、查询和值的头特定权重 \( W_H \in \mathbb{R}^{m \cdot h \times d_{\text{model}}} \) 用于将所有头输出合并。
为了展示特定特征的重要性，做出的修改如下：
\begin{equation}
    \text{InterpretableMultiHead}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \tilde{\mathbf{H}} \mathbf{W}_h
\end{equation}
\begin{equation}
    \begin{aligned}
        \mathbf{\tilde{H}} &= \tilde{A}(\mathbf{Q}, \mathbf{K}) \mathbf{V} \mathbf{W}_v, \\
        &= \left\{ \frac{1}{m_H} \sum_{h=1}^{m_H} A(\mathbf{Q} \mathbf{W}_Q^{(h)}, \mathbf{K} \mathbf{W}_K^{(h)}) \right\} \mathbf{V} \mathbf{W}_v, \\
        &= \frac{1}{m_H} \sum_{h=1}^{m_H} \text{Attention}(\mathbf{Q} \mathbf{W}_Q^{(h)}, \mathbf{K} \mathbf{W}_K^{(h)}, \mathbf{V} \mathbf{W}_v),
    \end{aligned}        
\end{equation}
式中：$\mathbf{W}_v \in \mathbb{R}^{d_{\text{model}} \times d_v}$是跨所有头共享的值的权重，$\mathbf{W}_h \in \mathbb{R}^{d_{\text{attn}} \times d_{\text{model}}}$
用于最终的线性映射。$\tilde{A}(\mathbf{Q}, \mathbf{K})$允许我们通过分析一组注意力权重来进行简单的可解释性研究。

在进行了时间特征处理层之后，我们应用注意力层。将所有的时间特征组合成单一的矩阵即$\bm{\varPhi }(t) = \left[ \bm{\phi} (t, -k), \ldots, \bm{\phi }(t, \tau_{\text{max}}) \right]^T$
并在每个时间点（$N = \tau _{max} + k + 1$）应用时域注意力:
\begin{equation}
    \mathbf{B}(t) = \text{InterpretableMultiHead}(\mathbf{\varPhi }(t), \mathbf{\varPhi }(t), \mathbf{\varPhi }(t)),
\end{equation}
生成了$\mathbf{B}(t) = \left[ \mathbf{\beta }(t, -k), \ldots, \mathbf{\beta }(t, \tau_{\max}) \right]$。在自注意力层之后，增加了一个额外
的门控层来促进训练：
\begin{equation}
    \boldsymbol{\delta}(t, n) = \text{LayerNorm}(\boldsymbol{\phi }(t, n)) + \text{GLU}_{\boldsymbol{\delta}}(\boldsymbol{\beta}(t, n)).
\end{equation}
\subsection{position-wise前馈层}
对自注意力层应用额外的非线性处理，此处依然使用门控残差网络：
\begin{equation}
    \boldsymbol{\psi}(t, n) = \text{GRN}_{\boldsymbol{\psi}}(\boldsymbol{\delta}(t, n))
\end{equation}
其中$ \text{GRN}_{\boldsymbol{\psi}}$的权重在整个层中共享。此处还应用了一个跳过整个transformer块的残差连接，为序列到序列层提供了直接的路径。
倘若不需要额外的复杂性，就可以得到一个更简单的模型。如下所示：
\begin{equation}
    \tilde{\boldsymbol{\psi}}(t, n) = \text{LayerNorm}(\tilde{\boldsymbol{\phi}}(t, n)) + \text{GLU}_{\tilde{\boldsymbol{\psi}}}(\tilde{\boldsymbol{\psi}}(t, n))
\end{equation}
\subsection{分位数预测层}
借鉴了MQRNN框架的思路，本文采用分位数回归预测作为模型的输出方式。具体来说就是回归模型在对目标产量进行预测的时候不只预测$y$的一个期望值$\hat{y}$，
而是预测出$y$的概率分布中不同百分位数（如10\%,50\%,90\%）的值。分位数预测是根据上一步输出的线性变换生成的：
\begin{equation}
    \hat{\boldsymbol{y}}(q, t, \tau) = \mathbf{W}_q \tilde{\boldsymbol{\psi}}(t, \tau) + \mathbf{b}_q
\end{equation}
本文采用联合最小化分位数损失来训练模型，并将所有的分位数方法相加，具体如式\eqref{eq:loss}所示。
\begin{equation}
    \mathcal{L}(\Omega, \mathbf{W}) = \sum_{y_t \in \Omega} \sum_{q \in \mathcal{Q} } \sum_{\tau=1}^{\tau_{\max}} \frac{\text{QL}(y_t, \hat{\boldsymbol{y}}(q, t - \tau, t), q)}{M_{\tau_{\max}}}
    \label{eq:loss}
\end{equation}
其中$\text{QL}(y,\hat{y},q)$为分位数损失，具体定义如下：
\begin{equation}
    \text{QL}(y, \hat{y}, q) = q(y - \hat{y})_+ + (1 - q)(\hat{y} - y)_+,
\end{equation}
在式\eqref{eq:loss}中，$\Omega$是包含M个样本的训练数据，$W$表示模型的权重，$\mathcal{Q}$是分位数的集合（用户可自行指定，本文使用$\mathcal{Q} = \{0.4, 0.6\}$）。
\section{实验对比分析}
\subsection{数据集描述与环境说明}
基于transformer的气井产量预测算法会在第\ref{sec:datafoc}节提供的数据集上进行验证。本次实验的硬件环境为处理器Inter(R) Xeon(R) Silver 4261 cpu @ 2.10Hz，
显卡GeForce RTX 3090，内存256G，磁盘1T，操作系统采用Windows 10，开发环境为Pycharm，Python环境为Anaconda-4.12.0 python=3.9。
\subsection{评估指标}
为了验证本章所提出的基于transformer的气井产量预测算法的有效性，使用两个指标用于评估。其中一个是平均绝对误差（Mean Absolute Error, MAE），其可以衡量
预测值与实际值之间的平均绝对偏差。公式如式\eqref{eq:MAE}所示。
\begin{equation}
    MAE(y, y') = \frac{1}{n} \sum_{i=1}^{n} |y_i - y'_i|
    \label{eq:MAE}
\end{equation}
另一个常用误差指标为累计产量的相对误差，公式如式\eqref{eq:RCPE}所示。
\begin{equation}
    RCPE = \frac{\sum_{i=1}^{n} |y_i| - \sum_{i=1}^{n} |y'_i|}{\sum_{i=1}^{n} |y_i|}
    \label{eq:RCPE}
\end{equation}
上面两式中，$i$表示索引，用于遍历数据集中的每一个数据点。例如，如果我们有一个包含多个观测值的数据集，$i$就用来表示这些观测值的序号，从第一个观测值
到第$n$个观测值。$y$表示真实值，也就是实际产量，$\hat{y}$表示预测值，也就是通过模型预测得到的产量。
\subsection{实验结果与对比分析}
（1）对比实验
根据前文所述，本问题需要同时对1000余口气井构建时间序列预测模型，且问题包含多种类型的协变量，因此选用基于注意力机制的seq2seq模型，lightGBM模型和TFT这三个可以
解决这类问题的模型来进行对比实验。为了展示各算法的预测性能，选出3口井的产量数据作为测试集进行测试，分别是：SN0016-05， SN0004-04，SN0012-10。这3口
井的近期平均产量分别位于大于2，1到2之间，小于1区间（单位：$10^4m^3$）。如表\ref{ta:compareTFT}所示。
\begin{table}[H]
    \centering
    \caption{不同算法预测结果对比表}

\end{table}
